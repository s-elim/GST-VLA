# GST-VLA Default Configuration
# ACCV 2026 Submission

# ──────────────────────────────────────────
# Architecture
# ──────────────────────────────────────────
model:
  # Encoders (FROZEN)
  img_size: 224
  patch_size: 14
  d_sem: 1152              # SigLIP ViT-SO400M/14
  depth_model_size: "vitl" # Depth Anything V2 ViT-L

  # GST (TRAINABLE - NOVEL)
  d_gst: 512               # GST output token dim
  N_g: 128                 # Number of Gaussian spatial tokens
  fourier_bands: 16        # 3D Fourier PE bands (→ dim = 3*2*16 = 96)

  # VLM (FROZEN for ACCV)
  vlm_model: "Qwen/Qwen2.5-VL-7B-Instruct"
  d_vlm: 3584              # Qwen2.5-VL-7B hidden dim

  # Action Expert (TRAINABLE)
  d_state: 14              # Robot state: 7 joint pos + 7 joint vel
  H: 16                    # Action chunk horizon
  d_action: 7              # Δpose(6) + gripper(1)
  n_expert_layers: 8
  n_euler_steps: 10        # ODE integration steps at inference
  lambda_ensemble: 0.01    # Temporal ensemble weight

# ──────────────────────────────────────────
# Training
# ──────────────────────────────────────────
training:
  # 3-Stage pipeline
  stages:
    1:
      epochs: 10
      lr: 1.0e-4
      description: "GST + Projector + Expert (all encoders frozen)"
    2:
      epochs: 20
      lr: 5.0e-5
      description: "+LoRA on VLM cross-attention projector"
    3:
      epochs: 10
      lr: 1.0e-5
      description: "Full fine-tune (LoRA + GST + Expert)"

  # Optimizer
  optimizer: "adamw"
  weight_decay: 0.01
  betas: [0.9, 0.95]
  grad_clip: 1.0

  # Batch & mixed precision
  batch_size: 32
  gradient_accumulation_steps: 4
  mixed_precision: true        # bf16

  # LR schedule
  scheduler: "cosine"
  warmup_steps: 500

# ──────────────────────────────────────────
# Losses
# ──────────────────────────────────────────
loss:
  lambda_depth: 0.1          # SiLog depth supervision weight
  lambda_opacity: 0.01       # GST opacity regularization
  lambda_scale: 0.001        # GST scale regularization
  target_sparsity: 0.3       # Target Gaussian opacity sparsity

# ──────────────────────────────────────────
# Data
# ──────────────────────────────────────────
data:
  # Primary benchmarks
  datasets:
    - name: "libero"
      split: "train"
      weight: 1.0
    - name: "metaworld"
      split: "train"
      weight: 0.5
    - name: "rlbench"
      split: "train"
      weight: 0.5

  # Camera setup
  camera_fov: 60.0
  depth_max: 5.0             # meters
  depth_min: 0.1             # meters

  # Augmentation
  augmentation:
    color_jitter: 0.4
    random_resized_crop: false  # Keep full image for depth alignment
    random_horizontal_flip: false
    normalize_mean: [0.485, 0.456, 0.406]
    normalize_std:  [0.229, 0.224, 0.225]

  num_workers: 8
  prefetch_factor: 2

# ──────────────────────────────────────────
# Evaluation
# ──────────────────────────────────────────
eval:
  freq_steps: 1000           # Evaluate every N steps
  metrics:
    - "success_rate"
    - "l2_distance"
    - "smoothness"
  n_eval_episodes: 50

# ──────────────────────────────────────────
# Logging
# ──────────────────────────────────────────
logging:
  project: "gst-vla-accv26"
  use_wandb: true
  log_3d_tokens: true        # Visualize Gaussian tokens (mu_3d, alpha)
  log_depth: true

# ──────────────────────────────────────────
# Hardware
# ──────────────────────────────────────────
hardware:
  num_gpus: 4
  gpu_type: "A100-80G"
  inference_latency_target_ms: 200   # ~5Hz control loop
